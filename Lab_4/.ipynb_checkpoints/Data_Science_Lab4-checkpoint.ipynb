{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Lab 4\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Wednesday, October 5th, 2016 at 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `IPython` notebook as well as the data file from Vocareum and complete locally.\n",
    "\n",
    "To submit your assignment, in Vocareum, upload (using the 'Upload' button on your Jupyter Dashboard) your solution to Vocareum as a single notebook with following file name format:\n",
    "\n",
    "`last_first_CourseNumber_HW4.ipynb`\n",
    "\n",
    "where `CourseNumber` is the course in which you're enrolled (CS 109a, Stats 121a, AC 209a). Submit your assignment in Vocareum using the 'Submit' button.\n",
    "\n",
    "**Avoid editing your file in Vocareum after uploading. If you need to make a change in a solution. Delete your old solution file from Vocareum and upload a new solution. Click submit only ONCE after verifying that you have uploaded the correct file. The assignment will CLOSE after you click the submit button.**\n",
    "\n",
    "Problems on homework assignments are equally weighted. The Challenge Question is required for AC 209A students and optional for all others. Student who complete the Challenge Problem as optional extra credit will receive +0.5% towards your final grade for each correct solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.linear_model import Ridge as Ridge_Reg\n",
    "from sklearn.linear_model import Lasso as Lasso_Reg\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import sklearn.preprocessing as Preprocessing\n",
    "import itertools as it\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "from itertools import combinations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0: Basic Information\n",
    "\n",
    "Fill in your basic information. \n",
    "\n",
    "### Part (a): Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Last, First]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Course Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CS 109a or STATS 121a or AC 209a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Who did you work with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[First and Land names of students with whom you have collaborated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All data sets can be found in the ``datasets`` folder and are in comma separated value (CSV) format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Variable selection and regularization\n",
    "\n",
    "The data set for this problem is provided in ``dataset_1.txt`` and contains 10 predictors and a response variable.\n",
    "\n",
    "### Part (a): Analyze correlation among predictors\n",
    "- By visually inspecting the data set, do find that some of the predictors are correlated amongst themselves?\n",
    "\n",
    "\n",
    "- Compute the cofficient of correlation between each pair of predictors, and visualize the matrix of correlation coefficients using a heat map. Do the predictors fall naturally into groups based on the correlation values?\n",
    "\n",
    "\n",
    "- If you were asked to select a minimal subset of predictors based on the correlation information in order to build a good regression model, how many predictors will you pick, and which ones will you choose? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959357</td>\n",
       "      <td>0.959357</td>\n",
       "      <td>0.959357</td>\n",
       "      <td>0.343727</td>\n",
       "      <td>0.524083</td>\n",
       "      <td>0.537768</td>\n",
       "      <td>0.435598</td>\n",
       "      <td>0.831999</td>\n",
       "      <td>0.153247</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.289394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.287376</td>\n",
       "      <td>0.513844</td>\n",
       "      <td>0.497775</td>\n",
       "      <td>0.452732</td>\n",
       "      <td>0.914609</td>\n",
       "      <td>0.367390</td>\n",
       "      <td>0.444473</td>\n",
       "      <td>-0.277574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995941</td>\n",
       "      <td>0.995941</td>\n",
       "      <td>0.995941</td>\n",
       "      <td>0.107294</td>\n",
       "      <td>0.097106</td>\n",
       "      <td>0.146751</td>\n",
       "      <td>0.136414</td>\n",
       "      <td>0.635926</td>\n",
       "      <td>0.535209</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>-0.513097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821732</td>\n",
       "      <td>0.821732</td>\n",
       "      <td>0.821732</td>\n",
       "      <td>0.202558</td>\n",
       "      <td>0.329504</td>\n",
       "      <td>0.359471</td>\n",
       "      <td>0.281453</td>\n",
       "      <td>0.106263</td>\n",
       "      <td>0.479327</td>\n",
       "      <td>0.256271</td>\n",
       "      <td>-0.182353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302423</td>\n",
       "      <td>0.302423</td>\n",
       "      <td>0.302423</td>\n",
       "      <td>0.184564</td>\n",
       "      <td>0.270263</td>\n",
       "      <td>0.293385</td>\n",
       "      <td>0.263866</td>\n",
       "      <td>0.378630</td>\n",
       "      <td>0.740241</td>\n",
       "      <td>0.468589</td>\n",
       "      <td>-0.625117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.959357  0.959357  0.959357  0.343727  0.524083  0.537768  0.435598   \n",
       "1  0.616969  0.616969  0.616969  0.287376  0.513844  0.497775  0.452732   \n",
       "2  0.995941  0.995941  0.995941  0.107294  0.097106  0.146751  0.136414   \n",
       "3  0.821732  0.821732  0.821732  0.202558  0.329504  0.359471  0.281453   \n",
       "4  0.302423  0.302423  0.302423  0.184564  0.270263  0.293385  0.263866   \n",
       "\n",
       "         7         8         9         10  \n",
       "0  0.831999  0.153247  0.005016  0.289394  \n",
       "1  0.914609  0.367390  0.444473 -0.277574  \n",
       "2  0.635926  0.535209  0.899457 -0.513097  \n",
       "3  0.106263  0.479327  0.256271 -0.182353  \n",
       "4  0.378630  0.740241  0.468589 -0.625117  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.loadtxt('datasets/dataset_1.txt', delimiter=',', skiprows=1)\n",
    "\n",
    "# Split predictors and response\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAF6CAYAAAAJaaMjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgy6JDXx/wEhGltPg0jMVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11179fd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute matrix of correlation coefficients\n",
    "corr_matrix = np.corrcoef(x.T)\n",
    "\n",
    "# Display heat map \n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "ax.pcolor(corr_matrix)\n",
    "\n",
    "ax.set_title('Heatmap of correlation matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Selecting minimal subset of predictors\n",
    "\n",
    "- Apply the variable selection methods discussed in class to choose a minimal subset of predictors that yield high prediction accuracy:\n",
    "    \n",
    "    - Exhaustive search\n",
    "    \n",
    "    - Step-wise forward selection **or** Step-wise backward selection  \n",
    "\n",
    "&emsp;&nbsp;&nbsp; In each method, use the Bayesian Information Criterion (BIC) to choose the subset size.\n",
    "\n",
    "- Do the chosen subsets match the ones you picked using the correlation matrix you had visualized in Part (a)?\n",
    "\n",
    "**Note**: You may use the `statsmodels`'s `OLS` module to fit a linear regression model and evaluate BIC. You may **not** use library functions that implement variable selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Apply Lasso and Ridge regression\n",
    "\n",
    "- Apply Lasso regression with regularization parameter $\\lambda = 0.01$ and fit a regression model.\n",
    "\n",
    "    - Identify the predictors that are assigned non-zero coefficients. Do these correspond to  the correlation matrix in Part (a)?\n",
    "\n",
    "\n",
    "- Apply Ridge regression with regularization parameter $\\lambda = 0.01$ and fit a regression model.\n",
    "\n",
    "    - Is there a difference between the model parameters you obtain different and those obtained from Lasso regression? If so, explain why.\n",
    "\n",
    "    - Identify the predictors that are assigned non-zero coefficients. Do these correspond to  the correlation matrix in Part (a)?\n",
    "\n",
    "\n",
    "- Is there anything peculiar that you observe about the coefficients Ridge regression assigns to the first three predictors? Do you observe the same with Lasso regression? Give an explanation for your observation.\n",
    "\n",
    "**Note**: You may use the `statsmodels` or `sklearn` to perform Lasso and Ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
